{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:52.411422Z",
     "start_time": "2020-08-07T03:37:50.826010Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# 查询系统可用的 GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# 确保有可用的 GPU 如果没有, 则会报错\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "# 设置参数,该段务必在运行jupyter的第一段代码执行，否则会无法初始化成功\n",
    "# 仅在需要时申请显存空间（程序初始运行时消耗很少的显存，随着程序的运行而动态申请显存）\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、Keras版本模型的保存与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 保存模型权重（model.save_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 保存整个模型\n",
    "- 保存HDF5文件（model.save)\n",
    "- 保存pb文件（tf.saved_model)\n",
    "二者的区别在于saved_model格式的模型可直接用于预测，但是save_model没有保存优化器的配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 保存完整的模型有很多应用场景，比如在浏览器中使用tensorflow.js加载运行，比如在移动设备中使用tensorflow lite 加载运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 保存模型与加载模型的案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:52.419866Z",
     "start_time": "2020-08-07T03:37:52.413875Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.random.random((1000,32))\n",
    "y_train = np.random.randint(10,size =(1000,))\n",
    "x_val = np.random.random((200,32))\n",
    "y_val = np.random.randint(10,size = (200,))\n",
    "x_test = np.random.random((200,32))\n",
    "y_test = np.random.randint(10,size = (200,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:52.428040Z",
     "start_time": "2020-08-07T03:37:52.421680Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = tf.keras.Input(shape = (32,), name = 'digits')\n",
    "    x = tf.keras.layers.Dense(64, activation= 'relu', name = 'dense_1')(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation= 'relu', name = 'dense_2')(x)\n",
    "    outputs = tf.keras.layers.Dense(10, name = 'predictions')(x)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-3),  # 编译模型添加了优化器和损失函数定义\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
    "    metrics = ['sparse_categorical_accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:54.880430Z",
     "start_time": "2020-08-07T03:37:52.430377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3211 - sparse_categorical_accuracy: 0.0890 - val_loss: 2.3163 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2946 - sparse_categorical_accuracy: 0.1210 - val_loss: 2.3094 - val_sparse_categorical_accuracy: 0.0950\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2819 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.3245 - val_sparse_categorical_accuracy: 0.0750\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2705 - sparse_categorical_accuracy: 0.1520 - val_loss: 2.3154 - val_sparse_categorical_accuracy: 0.0950\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2612 - sparse_categorical_accuracy: 0.1480 - val_loss: 2.3265 - val_sparse_categorical_accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9fc80aa100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size = 32, epochs = 5, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 方法一的模型保存方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:55.021515Z",
     "start_time": "2020-08-07T03:37:54.882478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08651663, -0.13452132,  0.22873767, ...,  0.14558567,\n",
       "        -0.00869111, -0.0766616 ],\n",
       "       [ 0.01916686, -0.11421013,  0.00244431, ..., -0.24580176,\n",
       "         0.40502584, -0.08497936],\n",
       "       [ 0.0091402 , -0.12411858,  0.07011697, ...,  0.07928359,\n",
       "         0.20610042, -0.05843626],\n",
       "       ...,\n",
       "       [-0.13298033, -0.19477229,  0.03819231, ..., -0.09306011,\n",
       "         0.27247036, -0.06529197],\n",
       "       [-0.23828475, -0.18567482,  0.42255732, ...,  0.11183605,\n",
       "        -0.03134666, -0.21639194],\n",
       "       [ 0.04447995, -0.17535129,  0.19586767, ...,  0.11469207,\n",
       "         0.1354679 , -0.03459841]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('adasd.h5')\n",
    "model.load_weights('adasd.h5')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:55.039269Z",
     "start_time": "2020-08-07T03:37:55.023535Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/mannul_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:55.058965Z",
     "start_time": "2020-08-07T03:37:55.041168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb08046aa90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/mannul_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:55.093438Z",
     "start_time": "2020-08-07T03:37:55.061583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08651663, -0.13452132,  0.22873767, ...,  0.14558567,\n",
       "        -0.00869111, -0.0766616 ],\n",
       "       [ 0.01916686, -0.11421013,  0.00244431, ..., -0.24580176,\n",
       "         0.40502584, -0.08497936],\n",
       "       [ 0.0091402 , -0.12411858,  0.07011697, ...,  0.07928359,\n",
       "         0.20610042, -0.05843626],\n",
       "       ...,\n",
       "       [-0.13298033, -0.19477229,  0.03819231, ..., -0.09306011,\n",
       "         0.27247036, -0.06529197],\n",
       "       [-0.23828475, -0.18567482,  0.42255732, ...,  0.11183605,\n",
       "        -0.03134666, -0.21639194],\n",
       "       [ 0.04447995, -0.17535129,  0.19586767, ...,  0.11469207,\n",
       "         0.1354679 , -0.03459841]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 方法二的模型保存方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:37:55.735721Z",
     "start_time": "2020-08-07T03:37:55.095217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hp/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: path_to_saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.08651663, -0.13452132,  0.22873767, ...,  0.14558567,\n",
       "        -0.00869111, -0.0766616 ],\n",
       "       [ 0.01916686, -0.11421013,  0.00244431, ..., -0.24580176,\n",
       "         0.40502584, -0.08497936],\n",
       "       [ 0.0091402 , -0.12411858,  0.07011697, ...,  0.07928359,\n",
       "         0.20610042, -0.05843626],\n",
       "       ...,\n",
       "       [-0.13298033, -0.19477229,  0.03819231, ..., -0.09306011,\n",
       "         0.27247036, -0.06529197],\n",
       "       [-0.23828475, -0.18567482,  0.42255732, ...,  0.11183605,\n",
       "        -0.03134666, -0.21639194],\n",
       "       [ 0.04447995, -0.17535129,  0.19586767, ...,  0.11469207,\n",
       "         0.1354679 , -0.03459841]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('path_to_saved_model',save_format='tf')\n",
    "new_model = tf.keras.models.load_model('path_to_saved_model')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 方法三的模型保存方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T03:39:26.969647Z",
     "start_time": "2020-08-07T03:39:26.859234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08651663, -0.13452132,  0.22873767, ...,  0.14558567,\n",
       "        -0.00869111, -0.0766616 ],\n",
       "       [ 0.01916686, -0.11421013,  0.00244431, ..., -0.24580176,\n",
       "         0.40502584, -0.08497936],\n",
       "       [ 0.0091402 , -0.12411858,  0.07011697, ...,  0.07928359,\n",
       "         0.20610042, -0.05843626],\n",
       "       ...,\n",
       "       [-0.13298033, -0.19477229,  0.03819231, ..., -0.09306011,\n",
       "         0.27247036, -0.06529197],\n",
       "       [-0.23828475, -0.18567482,  0.42255732, ...,  0.11183605,\n",
       "        -0.03134666, -0.21639194],\n",
       "       [ 0.04447995, -0.17535129,  0.19586767, ...,  0.11469207,\n",
       "         0.1354679 , -0.03459841]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('path_to_my_model.h5')\n",
    "new_model = tf.keras.models.load_model('path_to_my_model.h5')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3.4 方法四的模型保存方式,常用于模型的部署上使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T06:37:13.202321Z",
     "start_time": "2020-08-07T06:37:12.410152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_saved_model_version/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'tf_saved_model_version')\n",
    "restored_saved_model = tf.saved_model.load('tf_saved_model_version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T06:37:13.324170Z",
     "start_time": "2020-08-07T06:37:13.315156Z"
    }
   },
   "outputs": [],
   "source": [
    "f = restored_saved_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T06:37:14.111132Z",
     "start_time": "2020-08-07T06:37:14.089336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': <tf.Tensor: shape=(200, 10), dtype=float32, numpy=\n",
       " array([[ 0.08651663, -0.13452132,  0.22873767, ...,  0.14558567,\n",
       "         -0.00869111, -0.0766616 ],\n",
       "        [ 0.01916686, -0.11421013,  0.00244431, ..., -0.24580176,\n",
       "          0.40502584, -0.08497936],\n",
       "        [ 0.0091402 , -0.12411858,  0.07011697, ...,  0.07928359,\n",
       "          0.20610042, -0.05843626],\n",
       "        ...,\n",
       "        [-0.1329803 , -0.19477235,  0.03819229, ..., -0.09306011,\n",
       "          0.27247036, -0.06529202],\n",
       "        [-0.23828472, -0.18567485,  0.42255732, ...,  0.11183609,\n",
       "         -0.03134666, -0.2163919 ],\n",
       "        [ 0.04447995, -0.17535134,  0.19586769, ...,  0.11469213,\n",
       "          0.13546787, -0.03459835]], dtype=float32)>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T06:38:28.265623Z",
     "start_time": "2020-08-07T06:38:26.085778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['digits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 32)\n",
      "        name: serving_default_digits:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predictions'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /home/hp/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          digits: TensorSpec(shape=(None, 32), dtype=tf.float32, name='digits')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 32), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          digits: TensorSpec(shape=(None, 32), dtype=tf.float32, name='digits')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 32), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          digits: TensorSpec(shape=(None, 32), dtype=tf.float32, name='digits')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 32), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          digits: TensorSpec(shape=(None, 32), dtype=tf.float32, name='digits')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          digits: TensorSpec(shape=(None, 32), dtype=tf.float32, name='digits')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 32), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir tf_saved_model_version --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二、自定义版本模型的保存与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 保存checkpoint模型权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 保存整个模型\n",
    "- 保存HDF5文件（model.save)\n",
    "- 保存pb文件（tf.saved_model)\n",
    "二者的区别在于saved_model格式的模型可直接用于预测，但是save_model没有保存优化器的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T06:50:17.887620Z",
     "start_time": "2020-08-07T06:50:17.872354Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(MyModel,self).__init__(name = 'my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # 定义自己需要的层\n",
    "        self.dense_1 = tf.keras.layers.Dense(32, activation = 'relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(num_classes)\n",
    "        \n",
    "    @tf.function(input_signature = [tf.TensorSpec([None,32],tf.float32,name = 'inputs')])\n",
    "    def call(self, inputs):\n",
    "        # 定义前向传播\n",
    "        # 使用在（__init__)z中定义的层\n",
    "        x= self.dense_1(inputs)\n",
    "        return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T06:53:33.878796Z",
     "start_time": "2020-08-07T06:53:33.866251Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.random.random((1000,32))\n",
    "y_train = np.random.random((1000,10))\n",
    "x_val = np.random.random((200,32))\n",
    "y_val = np.random.random((200,10))\n",
    "x_test = np.random.random((200,32))\n",
    "y_test = np.random.random((200,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:03:47.422399Z",
     "start_time": "2020-08-07T07:03:47.416119Z"
    }
   },
   "outputs": [],
   "source": [
    "# 优化器\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:05:07.601029Z",
     "start_time": "2020-08-07T07:05:07.594939Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:06:04.941074Z",
     "start_time": "2020-08-07T07:06:04.916550Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义评估函数\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:07:57.518578Z",
     "start_time": "2020-08-07T07:07:57.505419Z"
    }
   },
   "outputs": [],
   "source": [
    "# 准备训练数据集\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:09:15.144323Z",
     "start_time": "2020-08-07T07:09:15.135045Z"
    }
   },
   "outputs": [],
   "source": [
    "# 准备测试数据集\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:44:03.949002Z",
     "start_time": "2020-08-07T07:44:02.939167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of epoch 0\n",
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "training loss (for one batch) at step 0:11.792417526245117\n",
      "seen so far: 64 samples\n",
      "training acc over epoch: 0.09301051497459412\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.171875\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.078125\n",
      "validation acc: 0.125\n",
      "training acc over epoch: 0.078125\n",
      "validation acc: 0.12999999523162842\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.12999999523162842\n",
      "training acc over epoch: 0.078125\n",
      "validation acc: 0.125\n",
      "training acc over epoch: 0.109375\n",
      "validation acc: 0.125\n",
      "training acc over epoch: 0.078125\n",
      "validation acc: 0.125\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.0625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.203125\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.15625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.15625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.0625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.10000000149011612\n",
      "validation acc: 0.11999999731779099\n",
      "start of epoch 1\n",
      "training loss (for one batch) at step 0:11.7383451461792\n",
      "seen so far: 64 samples\n",
      "training acc over epoch: 0.0625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.109375\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.15625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.15625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.109375\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.09375\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.078125\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.109375\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.109375\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.0625\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.10999999940395355\n",
      "training acc over epoch: 0.09375\n",
      "validation acc: 0.10999999940395355\n",
      "training acc over epoch: 0.09375\n",
      "validation acc: 0.10999999940395355\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.10999999940395355\n",
      "start of epoch 2\n",
      "training loss (for one batch) at step 0:12.090217590332031\n",
      "seen so far: 64 samples\n",
      "training acc over epoch: 0.140625\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.140625\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.09375\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.09375\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.140625\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.046875\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.109375\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.125\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.1875\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.078125\n",
      "validation acc: 0.11500000208616257\n",
      "training acc over epoch: 0.0\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.140625\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.03125\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.171875\n",
      "validation acc: 0.11999999731779099\n",
      "training acc over epoch: 0.15000000596046448\n",
      "validation acc: 0.11999999731779099\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(num_classes = 10)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print('start of epoch %d'  % (epoch,))\n",
    "    \n",
    "    # 遍历数据集的batch_size\n",
    "    for step,(x_batch_train,y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train)\n",
    "            loss_value = loss_fn(y_batch_train,logits)\n",
    "        grads = tape.gradient(loss_value,model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
    "        \n",
    "        # 更新训练集的metrics\n",
    "        train_acc_metric(y_batch_train,logits)\n",
    "        \n",
    "        # 每200 batch_size 打印一次结果\n",
    "        if step%200 == 0:\n",
    "            print('training loss (for one batch) at step %s:%s' %(step,float(loss_value)))\n",
    "            print('seen so far: %s samples' % ((step + 1) * 64))\n",
    "        \n",
    "        # 在每一个epoch结束的时候显示metrics\n",
    "        train_acc = train_acc_metric.result()\n",
    "        print('training acc over epoch: %s' % (float(train_acc),))\n",
    "        # 在每个epoch结束时重置训练指标\n",
    "        train_acc_metric.reset_states()\n",
    "        \n",
    "        #在每个epoch结束时运行一个验证集\n",
    "        for x_batch_val,y_batch_val in val_dataset:\n",
    "            val_logits = model(x_batch_val)\n",
    "            # 更新验证集metric\n",
    "            val_acc_metric(y_batch_val,val_logits)\n",
    "        val_acc = val_acc_metric.result()\n",
    "        val_acc_metric.reset_states()\n",
    "        print('validation acc: %s' % (float(val_acc),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义模型的保存方法一\n",
    "\n",
    "其实和上面的举例的四个方法是一致的，但是方法二是不行的，不能保存为h5格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:59:43.143787Z",
     "start_time": "2020-08-07T07:59:43.137699Z"
    }
   },
   "outputs": [],
   "source": [
    "# 此处不再赘述"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitcb11fcd8cdb441e4bf52994f94e346da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
