{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T08:22:08.795132Z",
     "start_time": "2020-08-07T08:22:07.259968Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# 查询系统可用的 GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# 确保有可用的 GPU 如果没有, 则会报错\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "# 设置参数,该段务必在运行jupyter的第一段代码执行，否则会无法初始化成功\n",
    "# 仅在需要时申请显存空间（程序初始运行时消耗很少的显存，随着程序的运行而动态申请显存）\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、自定义层\n",
    "\n",
    "- 使用的主要数据结构是layer\n",
    "- 实现自定义层的最佳方法是扩展tf.keras.layers.layer 类并实现\n",
    "1. __init__ ： 可以在其中进行所有与输入无关的初始化，定义相关的层\n",
    "2. build: 知道输入张量的形状并可以进行其余的初始化\n",
    "3. call:在这里进行前向传播\n",
    "注意：不一定需要在build中创建变量时，也可以在__init__中创建他们。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.keras.Model 和 tf.keras.layers.layer 区别和联系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过继承 tf.keras.Model 编写自己的模型类\n",
    "- 通过继承tf.keras.layers.layer 编写自己的层\n",
    "- tf.keras中的模型和层都是继承tf.Module实现的\n",
    "- tf.keras.Model继承tf.keras.layers.layer实现的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义一个线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T09:01:48.020172Z",
     "start_time": "2020-08-07T09:01:47.966833Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data =iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:2] # 数据本身就算array，所以输入是完全可以直接被神经网络接收的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T09:02:38.525887Z",
     "start_time": "2020-08-07T09:02:38.508310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T09:02:48.445113Z",
     "start_time": "2020-08-07T09:02:48.435967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义线性模型的方法1 --- 最基础的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T09:17:35.672329Z",
     "start_time": "2020-08-07T09:17:34.473477Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer linear is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,units =1, input_dim = 4):\n",
    "        super(Linear,self).__init__()\n",
    "        w_init = tf.random_normal_initializer() # 随机初始化\n",
    "        self.w = tf.Variable(initial_value = w_init(shape = (input_dim,units),dtype = 'float32'), trainable = True)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(initial_value = b_init(shape = (units,), dtype = 'float32'),trainable = True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs,self.w) + self.b\n",
    "\n",
    "x = tf.constant(data)\n",
    "linear_layer = Linear(units =1,input_dim = 4)\n",
    "y = linear_layer(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T09:20:26.755945Z",
     "start_time": "2020-08-07T09:20:26.746287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.32608113],\n",
       "       [0.28710207],\n",
       "       [0.2979414 ],\n",
       "       [0.27652025],\n",
       "       [0.32865408],\n",
       "       [0.3403099 ],\n",
       "       [0.29857594],\n",
       "       [0.3103535 ],\n",
       "       [0.26214537],\n",
       "       [0.29026067]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义线性模型的方法2-- 使用self.add_weight创建变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T09:26:50.284951Z",
     "start_time": "2020-08-07T09:26:50.264417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer linear_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,units =1, input_dim = 4):\n",
    "        super(Linear,self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim,units),initializer='random_normal',trainable = True)\n",
    "        self.b = self.add_weight(shape=(units,),initializer='zeros',trainable = True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs,self.w) + self.b\n",
    "    \n",
    "x = tf.constant(data)\n",
    "linear_layer = Linear(units =1,input_dim = 4)\n",
    "y = linear_layer(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T09:26:57.264204Z",
     "start_time": "2020-08-07T09:26:57.255679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-0.08645435],\n",
       "       [-0.12379789],\n",
       "       [-0.08351722],\n",
       "       [-0.10863582],\n",
       "       [-0.0715258 ],\n",
       "       [-0.10008639],\n",
       "       [-0.07180031],\n",
       "       [-0.10114945],\n",
       "       [-0.10675558],\n",
       "       [-0.12223301]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义线性模型的方法3 --- build函数中创建变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,units =32):\n",
    "        super(Linear,self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape = (input_shape[-1],self.units),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True)\n",
    "        self.b = self.add_weight(shape = (self.units,),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True)\n",
    "        super(Linear,self).build(input_shape)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs,self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer linear_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(data)\n",
    "linear_layer = Linear(units = 1)\n",
    "y = linear_layer(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [<tf.Variable 'linear_5/Variable:0' shape=(4, 1) dtype=float32, numpy=\n",
      "array([[ 0.09345417],\n",
      "       [-0.03406332],\n",
      "       [ 0.01242764],\n",
      "       [-0.00207755]], dtype=float32)>, <tf.Variable 'linear_5/Variable:0' shape=(1,) dtype=float32, numpy=array([0.03450685], dtype=float32)>]\n",
      "non-trainable weight: []\n",
      "trainable weight: [<tf.Variable 'linear_5/Variable:0' shape=(4, 1) dtype=float32, numpy=\n",
      "array([[ 0.09345417],\n",
      "       [-0.03406332],\n",
      "       [ 0.01242764],\n",
      "       [-0.00207755]], dtype=float32)>, <tf.Variable 'linear_5/Variable:0' shape=(1,) dtype=float32, numpy=array([0.03450685], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print('weight:',linear_layer.weights)\n",
    "print('non-trainable weight:',linear_layer.non_trainable_weights) # 不参与训练的张量\n",
    "print('trainable weight:',linear_layer.trainable_weights) # 参与训练的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义层的注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、需要注意在自定义网络层时要重写get_config,示例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,units =32, **kwargs):\n",
    "        self.units = units\n",
    "        super(MyDense,self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "     # build方法一般定义Layer需要被训练的参数   \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.w = self.add_weight(shape = (input_shape[-1],self.units),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True,\n",
    "        name = 'w')\n",
    "\n",
    "        self.b = self.add_weight(shape = (self.units,),\n",
    "        initializer = 'random_normal',\n",
    "        trainable = True,\n",
    "        name = 'b')\n",
    "\n",
    "        super(MyDense,self).build(input_shape) # 相当于设置self.build = True\n",
    "\n",
    "    # call方法一般定义正向传播运算逻辑，__call__方法调用了它\n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs,self.w) + self.b\n",
    "\n",
    "    # 如果要让自定义的Layer通过Funcitional API 组合成模型时可以序列化，需要自定义get_config方法\n",
    "    def get_config(self):\n",
    "        config = super(MyDense,self).get_config()\n",
    "        config.update({'units':self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data =iris.data\n",
    "labels = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个网络 函数式编程定义的网络\n",
    "inputs = tf.keras.Input(shape=(4,))\n",
    "x = MyDense(units = 16)(inputs) # 设置含有16个神经元的units中间层\n",
    "x = tf.nn.tanh(x) # 使用tanh函数对神经元做转换\n",
    "x = MyDense(units = 3)(x) # 定义输入的神经元的个数\n",
    "predictions = tf.nn.softmax(x) # 使用softmax做转换\n",
    "model = tf.keras.Model(inputs = inputs,outputs = predictions) # 通过一个方法对输入和输出联系起来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![鸢尾花数据集演示简单的神经网络结构](/home/hp/git/learningzone/huangpei/eat_tensorflow2_in_30_days/markdown_pics/鸢尾花数据集示意简单神经网络.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data,labels.reshape(150,1)),axis = -1)\n",
    "np.random.shuffle(data) # 对数据做随机初始化，然后打乱数据的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,-1] # 取最后一列数据\n",
    "data = data[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0975 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0954 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0935 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0916 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0896 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0871 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0850 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0816 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0783 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0744 - sparse_categorical_accuracy: 0.3400\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0698 - sparse_categorical_accuracy: 0.4600\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0649 - sparse_categorical_accuracy: 0.5933\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0590 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0522 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0446 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0360 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0270 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0164 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0052 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9933 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9811 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9684 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9561 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9434 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9319 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9205 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9097 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9001 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8911 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8830 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8749 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8682 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8620 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8563 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8510 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8463 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8422 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8383 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8346 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8312 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8281 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8251 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8222 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8195 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8169 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8143 - sparse_categorical_accuracy: 0.6733\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8117 - sparse_categorical_accuracy: 0.6733\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8092 - sparse_categorical_accuracy: 0.6800\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8067 - sparse_categorical_accuracy: 0.6867\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8040 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8014 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7987 - sparse_categorical_accuracy: 0.7067\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7961 - sparse_categorical_accuracy: 0.7200\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7938 - sparse_categorical_accuracy: 0.7400\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7905 - sparse_categorical_accuracy: 0.7600\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7879 - sparse_categorical_accuracy: 0.7733\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7849 - sparse_categorical_accuracy: 0.7933\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7819 - sparse_categorical_accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7793 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7759 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7727 - sparse_categorical_accuracy: 0.8733\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7697 - sparse_categorical_accuracy: 0.8733\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7665 - sparse_categorical_accuracy: 0.8933\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7637 - sparse_categorical_accuracy: 0.9200\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7600 - sparse_categorical_accuracy: 0.9467\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7569 - sparse_categorical_accuracy: 0.9267\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7543 - sparse_categorical_accuracy: 0.9133\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7508 - sparse_categorical_accuracy: 0.9533\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7472 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7437 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7404 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7373 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7344 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7311 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7289 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7251 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7219 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7188 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7158 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7135 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7100 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7075 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7051 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7019 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6993 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6967 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6942 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.9800\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6870 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6847 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6827 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6788 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6761 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6739 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6722 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6702 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6684 - sparse_categorical_accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6665 - sparse_categorical_accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fce607d6280>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义优化器\n",
    "# 定义损失函数 交叉熵损失函数\n",
    "# 定义评估函数 acc\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.fit(data,labels, batch_size = 32, epochs = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "my_dense_4 (MyDense)         (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Tanh_2 (TensorFl [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "my_dense_5 (MyDense)         (None, 3)                 51        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Softmax_2 (Tenso [(None, 3)]               0         \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特别注意，如果前面不定义get_config，那么就没办法获取参数用于保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_model_tf_version.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、若模型保存model.save报错如下图，则可能是自定义层的build中创建初始矩阵的时候，name属性没定义，导致报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 错误类型\n",
    "RuntimeError:Unable to create link (name already exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、当自定义网络层并且有效保存模型后，希望使用tf.keras.models.load_model进行模型加载时，可能报错如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 错误类型\n",
    "ValueError:Unknown layer:MyDense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决方法：建立一个字典，键是自定义网络层时设定该层的名字，值是该自定义网络层的类名，该字典用于加载模型的时候使用，然后在tf.keras.models.load_model内传入custom_objects告知如何解析重建自定义网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新加载如下\n",
    "_custom_objects = {'MyDense':MyDense}\n",
    "\n",
    "new_model = tf.keras.models.load_model('keras_model_tf_version.h5',custom_objects = _custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = new_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 1, 0, 0, 2, 2, 2, 0, 2, 1, 0, 2,\n",
       "       1, 0, 0, 1, 1, 2, 2, 0, 0, 1, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0,\n",
       "       2, 0, 2, 1, 0, 0, 2, 2, 2, 1, 0, 0, 1, 2, 1, 1, 1, 0, 0, 2, 1, 1,\n",
       "       1, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 1, 0, 0, 2,\n",
       "       2, 0, 0, 2, 0, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 2,\n",
       "       2, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 2, 1, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 0., 0., 2., 2., 1., 2., 0., 0., 2., 2., 2., 2., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 2., 0., 1., 2., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 2., 2., 2., 0., 2., 1., 0., 2., 1., 0., 0., 1., 1., 2., 2.,\n",
       "       0., 0., 1., 2., 0., 1., 2., 2., 1., 1., 2., 2., 1., 0., 0., 2., 0.,\n",
       "       2., 1., 0., 0., 2., 2., 2., 1., 0., 0., 1., 2., 1., 1., 1., 0., 0.,\n",
       "       2., 1., 1., 1., 0., 0., 0., 2., 2., 0., 2., 0., 2., 0., 2., 2., 1.,\n",
       "       2., 1., 2., 1., 1., 0., 0., 1., 2., 0., 0., 2., 0., 0., 2., 1., 2.,\n",
       "       2., 2., 2., 1., 2., 1., 1., 1., 0., 1., 1., 0., 2., 2., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 2., 0., 2., 1., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "四、当自定义一个网络层其名字和默认的tf.keras网络层一样的时候，可能会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "五、当实现自定义网络层的时候，最好统一在初始化的时候传入可变参数**kwargs,这是因为在model推理的时候，有时我们需要对所有构成该模型的网络层进行统一的传参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitcb11fcd8cdb441e4bf52994f94e346da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
