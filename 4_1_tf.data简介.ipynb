{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:35:09.727950Z",
     "start_time": "2021-02-23T11:35:09.717545Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# 查询系统可用的 GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# 确保有可用的 GPU 如果没有, 则会报错\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "# 设置参数,该段务必在运行jupyter的第一段代码执行，否则会无法初始化成功\n",
    "# 仅在需要时申请显存空间（程序初始运行时消耗很少的显存，随着程序的运行而动态申请显存）\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. tf.data初探\n",
    "- 面对一堆格式不一的原始数据文件？读入程序的过程往往十分繁琐？运行的效率上不尽如人意？\n",
    "- TensorFlow提供了tf.data这一模块，包括了一套灵活的数据集构建API，能够帮助我们快速高效的构建数据输入的流水线，尤其适用于数据量巨大的场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 包含三个类\n",
    "- tf.data.Dataset类\n",
    "- tf.data.TFRecordDataset类\n",
    "- tf.data.TextLineDataset类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dataset类\n",
    "- tf.data的核心就是tf.data.Dataset类，提供了对数据集的高层封装。\n",
    "- tf.data.Dataset由一系列的可迭代访问的元素（element）组成，每个元素包含一个或多个张量。Dataset可以看作是相同类型“元素”的有序列表\n",
    "比如说，对于一个由图像组成的数据集，每个元素可以是一个形状为  [长 * 宽 * 通道数] 的图片张量，也可以是由图片张量和图片标签张量组成的元组（Tuple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data.Dataset类创建数据集，对数据集实例化，最常用的如：\n",
    "- tf.data.Dataset.from_tensors()：创建Dataset对象，合并输入并返回具有单个元素的数据集\n",
    "- tf.data.Dataset.from_tensor_slices():创建一个Dataset对象，输入可以是一个或者多个tensor,若是多个tensor,需要以元组或者字典等形式组装起来\n",
    "- tf.data.Dataset.from_generator():迭代生成所需的数据集，一般数据量较大的时候使用\n",
    "\n",
    "\n",
    "注：Dataset可以看作是相同类型的元素的有序列表，在实际使用时，单个元素可以是向量，也可以是字符串，图片，甚至是tuple，或者dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from_tensors和from_tensors_slices区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from_tensors()函数会把传入的tensor当做一个元素，但是from_tensors_slices会把传入的tensor除开第0维之后的大小当做元素个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.data.Dataset数据集处理\n",
    "tf.data.Dataset 类为我们提供了多种数据集预处理方法。最常用的如下：\n",
    "\n",
    "- tf.data.Dataset.map(f):对数据集中的每个元素应用函数f，得到一个新的数据集（这部分往往集合tf.io进行读写和解码文件，tf.image进行图像处理）；\n",
    "- tf.data.Dataset.shuffle(buffer_size):将数据集打乱（设定一个固定大小的缓冲区（Buffer),取出前buffer_size个元素放入，并从缓冲区中随机采样，采样后的数据用后续数据替换）\n",
    "- tf.data.Dataset.batch(batch_size)：将数据集分成批次，即对每batch_size个元素，使用tf.stack()在第0维度合并，成为一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T03:27:31.020057Z",
     "start_time": "2021-02-21T03:27:31.011515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function from_tensor_slices in module tensorflow.python.data.ops.dataset_ops:\n",
      "\n",
      "from_tensor_slices(tensors)\n",
      "    Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "    \n",
      "    The given tensors are sliced along their first dimension. This operation\n",
      "    preserves the structure of the input tensors, removing the first dimension\n",
      "    of each tensor and using it as the dataset dimension. All input tensors\n",
      "    must have the same size in their first dimensions.\n",
      "    \n",
      "    >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2, 3]\n",
      "    \n",
      "    >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      "    \n",
      "    >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      "    >>> # scalar tensors.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [(1, 3, 5), (2, 4, 6)]\n",
      "    \n",
      "    >>> # Dictionary structure is also preserved.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      "    >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      "    ...                                       {'a': 2, 'b': 4}]\n",
      "    True\n",
      "    \n",
      "    >>> # Two tensors can be combined into one Dataset object.\n",
      "    >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      "    >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      "    >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      "    >>> # Both the features and the labels tensors can be converted\n",
      "    >>> # to a Dataset object separately and combined after.\n",
      "    >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      "    >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      "    >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      "    >>> # A batched feature and label set can be converted to a Dataset\n",
      "    >>> # in similar fashion.\n",
      "    >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      "    ...                                 [[2, 1], [1, 2]],\n",
      "    ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      "    >>> batched_labels = tf.constant([['A', 'A'],\n",
      "    ...                               ['B', 'B'],\n",
      "    ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      "    >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      "    >>> for element in dataset.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (array([[1, 3],\n",
      "           [2, 3]], dtype=int32), array([[b'A'],\n",
      "           [b'A']], dtype=object))\n",
      "    (array([[2, 1],\n",
      "           [1, 2]], dtype=int32), array([[b'B'],\n",
      "           [b'B']], dtype=object))\n",
      "    (array([[3, 3],\n",
      "           [3, 2]], dtype=int32), array([[b'A'],\n",
      "           [b'B']], dtype=object))\n",
      "    \n",
      "    Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      "    enabled, the values will be embedded in the graph as one or more\n",
      "    `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      "    memory and run into byte limits of graph serialization. If `tensors`\n",
      "    contains one or more large NumPy arrays, consider the alternative described\n",
      "    in [this guide](\n",
      "    https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      "    \n",
      "    Args:\n",
      "      tensors: A dataset element, with each component having the same size in\n",
      "        the first dimension.\n",
      "    \n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.data.Dataset.from_tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T03:39:44.336911Z",
     "start_time": "2021-02-21T03:39:44.328671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function from_generator in module tensorflow.python.data.ops.dataset_ops:\n",
      "\n",
      "from_generator(generator, output_types, output_shapes=None, args=None)\n",
      "    Creates a `Dataset` whose elements are generated by `generator`.\n",
      "    \n",
      "    The `generator` argument must be a callable object that returns\n",
      "    an object that supports the `iter()` protocol (e.g. a generator function).\n",
      "    The elements generated by `generator` must be compatible with the given\n",
      "    `output_types` and (optional) `output_shapes` arguments.\n",
      "    \n",
      "    >>> import itertools\n",
      "    >>>\n",
      "    >>> def gen():\n",
      "    ...   for i in itertools.count(1):\n",
      "    ...     yield (i, [1] * i)\n",
      "    >>>\n",
      "    >>> dataset = tf.data.Dataset.from_generator(\n",
      "    ...      gen,\n",
      "    ...      (tf.int64, tf.int64),\n",
      "    ...      (tf.TensorShape([]), tf.TensorShape([None])))\n",
      "    >>>\n",
      "    >>> list(dataset.take(3).as_numpy_iterator())\n",
      "    [(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]\n",
      "    \n",
      "    Note: The current implementation of `Dataset.from_generator()` uses\n",
      "    `tf.numpy_function` and inherits the same constraints. In particular, it\n",
      "    requires the `Dataset`- and `Iterator`-related operations to be placed\n",
      "    on a device in the same process as the Python program that called\n",
      "    `Dataset.from_generator()`. The body of `generator` will not be\n",
      "    serialized in a `GraphDef`, and you should not use this method if you\n",
      "    need to serialize your model and restore it in a different environment.\n",
      "    \n",
      "    Note: If `generator` depends on mutable global variables or other external\n",
      "    state, be aware that the runtime may invoke `generator` multiple times\n",
      "    (in order to support repeating the `Dataset`) and at any time\n",
      "    between the call to `Dataset.from_generator()` and the production of the\n",
      "    first element from the generator. Mutating global variables or external\n",
      "    state can cause undefined behavior, and we recommend that you explicitly\n",
      "    cache any external state in `generator` before calling\n",
      "    `Dataset.from_generator()`.\n",
      "    \n",
      "    Args:\n",
      "      generator: A callable object that returns an object that supports the\n",
      "        `iter()` protocol. If `args` is not specified, `generator` must take no\n",
      "        arguments; otherwise it must take as many arguments as there are values\n",
      "        in `args`.\n",
      "      output_types: A nested structure of `tf.DType` objects corresponding to\n",
      "        each component of an element yielded by `generator`.\n",
      "      output_shapes: (Optional.) A nested structure of `tf.TensorShape` objects\n",
      "        corresponding to each component of an element yielded by `generator`.\n",
      "      args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated\n",
      "        and passed to `generator` as NumPy-array arguments.\n",
      "    \n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.data.Dataset.from_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.TFRecordDataset类\n",
    "- 对于特别巨大而无法完整载入内存的数据集，我们可以先将数据集处理为TFRecord格式，然后tf.data.TFRecordDataset()进行载入。\n",
    "\n",
    "- TFRecord 是 TensorFlow中的数据集存储格式。当我们将数据集整理成TFRecord格式后，TensorFlow就可以高效的读取和处理这些数据集，从而帮助我们更高效地进行大规模的模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.TFRecordDataset(\n",
    "    filenames,  # tf.string张量，值为一个或者多个文件名\n",
    "    compression_type=None, # tf.string标量， 值为\"\",不压缩，ZLIB 或者 GZIP 之一\n",
    "    buffer_size=None, # tf.int64标量，表示读取缓冲区中的字节数\n",
    "    num_parallel_reads=None # tf.int64标量，表示要并行读取的文件数\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 定义Feature结构，告诉解码器每个Feature的类型是什么\n",
    " feature_description = {\n",
    "     'image':tf.io.FixedLenFeature([],tf.string),\n",
    "     'label':tf.io.FixedLenFeature([],tf.int64),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_example(example_strin):\n",
    "    # 将TFRecord 文件中的每一个序列化的tf.train.Example 解码\n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "\n",
    "    feature_description['image'] = tf.io.decode_jpeg(feature_dict['image']) #解码JPEG图片\n",
    "    feature_description['image'] = tf.image.resize(feature_dict['image'],[256,256])/255.0\n",
    "\n",
    "    return feature_dict['image'],feature_dict['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset('train.tfrecord') # 读取TFRcord文件\n",
    "\n",
    "train_dataset = train_dataset.map(_parse_example)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=23000)\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.TextLineDataset类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.data.TextLineDataset 提供了一种或多个文本文件这种提取行的简单方法\n",
    "\n",
    "- 给定一个或者多个文件名，TextLineDataset会为这些文件的每行生成一个字符串值元素，像TFRecordDataset一样，TextLineDataset将filenames 视为 tf.Tensor。\n",
    "\n",
    "- 类中保存的元素，文中一行，就是一个元素，是string类型的tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.TextLineDataset(\n",
    "    filenames,  # 值为一个或者多个文件名\n",
    "    compression_type=None, # tf.string张量，值为\"\"（不压缩）、ZLIB 或者GZIP之一\n",
    "    buffer_size=None, # tf.int64标量，表示读取缓冲区中的字节数\n",
    "    num_parallel_reads=None # tf.int64标量，表示要并行读取的文件数\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tf.data.TextLineDataset使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_lines  = tf.data.TextLineDataset(['./data/titanic/train.csv','./data/titanic/eval.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_func(line):\n",
    "    line = tf.strings.split(line, sep = ',')\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = titanic_lines.skip(1).map(data_func) # 跳过表头名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'493' b'0' b'1' b'\"Molson' b' Mr. Harry Markland\"' b'male' b'55.0' b'0'\n",
      " b'0' b'113787' b'30.5' b'C30' b'S'], shape=(13,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for line in titanic_data: # 输出多个Tensor\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码实战演示环节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dataset类读取numpy数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最基础的建立tf.data.Dataset的方法是使用tf.data.Dataset.from_tensor_slices()，适用于数据量较小（能够整个装进内存）的情况\n",
    "\n",
    "具体而言，如果我们的数据集中的所有元素通过张量的第0维，拼接成一个大的张量（例如，上一节的MNIST数据集的训练集是一个[60000,28,28,1]的张量，表示了6万张28*28的单通道灰色图像），那么我们提供一个这样的张量或者第0维大小相同的多个张量作为输入。即可按张量的第0维展开来构建数据集，数据集的元素数量为张量第0维的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tmp = '/home/hp/.local/lib/python3.8/site-packages/tensorflow/keras/datasets/'\n",
    "mnist = np.load(path_tmp + \"mnist.npz\")\n",
    "x_train, y_train, x_test, y_test = mnist['x_train'],mnist['y_train'],mnist['x_test'],mnist['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)) #数据小可以完全载入内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"264.912187pt\" version=\"1.1\" viewBox=\"0 0 250.568125 264.912187\" width=\"250.568125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 264.912187 \n",
       "L 250.568125 264.912187 \n",
       "L 250.568125 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 25.928125 240.2325 \n",
       "L 243.368125 240.2325 \n",
       "L 243.368125 22.7925 \n",
       "L 25.928125 22.7925 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pa69167d8b2)\">\n",
       "    <image height=\"218\" id=\"image17a28be409\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"25.928125\" xlink:href=\"data:image/png;base64,\n",
       "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\" y=\"-22.2325\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mf4032a76f0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.810982\" xlink:href=\"#mf4032a76f0\" y=\"240.2325\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 4.4375 36.328125 \n",
       "Q 4.4375 56.34375 11.078125 66.625 \n",
       "Q 17.71875 76.90625 30.328125 76.90625 \n",
       "Q 54.34375 76.90625 54.34375 38.140625 \n",
       "Q 54.34375 19 47.578125 8.859375 \n",
       "Q 40.828125 -1.265625 28.609375 -1.265625 \n",
       "Q 17.09375 -1.265625 10.765625 8.34375 \n",
       "Q 4.4375 17.96875 4.4375 36.328125 \n",
       "z\n",
       "M 14.203125 36.765625 \n",
       "Q 14.203125 6.640625 29.5 6.640625 \n",
       "Q 44.53125 6.640625 44.53125 37.25 \n",
       "Q 44.53125 68.953125 29.78125 68.953125 \n",
       "Q 14.203125 68.953125 14.203125 36.765625 \n",
       "z\n",
       "\" id=\"MicrosoftYaHei-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(26.878951 255.22625)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"68.639554\" xlink:href=\"#mf4032a76f0\" y=\"240.2325\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.640625 11.625 \n",
       "Q 16.265625 6.640625 24.515625 6.640625 \n",
       "Q 32.328125 6.640625 37.109375 11 \n",
       "Q 41.890625 15.375 41.890625 22.609375 \n",
       "Q 41.890625 29.890625 37.03125 33.890625 \n",
       "Q 32.171875 37.890625 22.953125 37.890625 \n",
       "Q 18.5 37.890625 10.984375 37.203125 \n",
       "L 10.984375 75.640625 \n",
       "L 48.1875 75.640625 \n",
       "L 48.1875 67.1875 \n",
       "L 19.875 67.1875 \n",
       "L 19.875 45.796875 \n",
       "Q 24.125 46.046875 26.265625 46.046875 \n",
       "Q 38.234375 46.046875 44.921875 39.984375 \n",
       "Q 51.609375 33.9375 51.609375 23.296875 \n",
       "Q 51.609375 12.3125 44.421875 5.515625 \n",
       "Q 37.25 -1.265625 24.609375 -1.265625 \n",
       "Q 14.015625 -1.265625 8.640625 1.859375 \n",
       "z\n",
       "\" id=\"MicrosoftYaHei-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(65.707522 255.22625)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.468125\" xlink:href=\"#mf4032a76f0\" y=\"240.2325\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 10 -->\n",
       "      <defs>\n",
       "       <path d=\"M 52.59375 0 \n",
       "L 9.234375 0 \n",
       "L 9.234375 8.25 \n",
       "L 26.171875 8.25 \n",
       "L 26.171875 65.671875 \n",
       "L 8.796875 60.640625 \n",
       "L 8.796875 69.4375 \n",
       "L 35.6875 77.25 \n",
       "L 35.6875 8.25 \n",
       "L 52.59375 8.25 \n",
       "z\n",
       "\" id=\"MicrosoftYaHei-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(101.604063 255.22625)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-49\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"146.296696\" xlink:href=\"#mf4032a76f0\" y=\"240.2325\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(140.432634 255.22625)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-49\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"185.125268\" xlink:href=\"#mf4032a76f0\" y=\"240.2325\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 51.171875 0 \n",
       "L 5.171875 0 \n",
       "L 5.171875 8.296875 \n",
       "L 27.15625 30.21875 \n",
       "Q 36.234375 39.3125 39.3125 44.609375 \n",
       "Q 42.390625 49.90625 42.390625 55.5625 \n",
       "Q 42.390625 62.015625 38.765625 65.453125 \n",
       "Q 35.15625 68.890625 28.328125 68.890625 \n",
       "Q 18.21875 68.890625 9.03125 60.296875 \n",
       "L 9.03125 70.015625 \n",
       "Q 17.96875 76.90625 29.828125 76.90625 \n",
       "Q 40.046875 76.90625 45.953125 71.390625 \n",
       "Q 51.859375 65.875 51.859375 56.546875 \n",
       "Q 51.859375 49.515625 48.0625 42.75 \n",
       "Q 44.28125 35.984375 33.734375 25.53125 \n",
       "L 16.5 8.6875 \n",
       "L 16.5 8.5 \n",
       "L 51.171875 8.5 \n",
       "z\n",
       "\" id=\"MicrosoftYaHei-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(179.261205 255.22625)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-50\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"223.953839\" xlink:href=\"#mf4032a76f0\" y=\"240.2325\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(218.089777 255.22625)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-50\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"mbd8c7381c7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"25.928125\" xlink:href=\"#mbd8c7381c7\" y=\"26.675357\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.064063 30.672232)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"25.928125\" xlink:href=\"#mbd8c7381c7\" y=\"65.503929\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.064063 69.500804)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"25.928125\" xlink:href=\"#mbd8c7381c7\" y=\"104.3325\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 108.329375)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-49\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"25.928125\" xlink:href=\"#mbd8c7381c7\" y=\"143.161071\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 147.157946)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-49\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"25.928125\" xlink:href=\"#mbd8c7381c7\" y=\"181.989643\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 185.986518)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-50\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"25.928125\" xlink:href=\"#mbd8c7381c7\" y=\"220.818214\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 224.815089)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#MicrosoftYaHei-50\"/>\n",
       "       <use x=\"58.642578\" xlink:href=\"#MicrosoftYaHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 25.928125 240.2325 \n",
       "L 25.928125 22.7925 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 243.368125 240.2325 \n",
       "L 243.368125 22.7925 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 25.928125 240.2325 \n",
       "L 243.368125 240.2325 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 25.928125 22.7925 \n",
       "L 243.368125 22.7925 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_13\">\n",
       "    <!-- 5 -->\n",
       "    <g transform=\"translate(131.129688 16.7925)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#MicrosoftYaHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pa69167d8b2\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"25.928125\" y=\"22.7925\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in mnist_dataset:\n",
    "    plt.title(label.numpy())\n",
    "    plt.imshow(image.numpy()[:,:,0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thal'] = pd.Categorical(df['thal'])\n",
    "df['thal'] = df.thal.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat, targ in dataset.take(5):\n",
    "    print('feature:{}, target:{}').format(feat, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从Python generator构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255, rotation_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers = './flower_photos/flower_photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen():\n",
    "    gen = img_gen.flow_from_directory(flowers)\n",
    "    for (x,y) in gen:\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_generator(\n",
    "    Gen,\n",
    "    output_types=(tf.float32, tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in ds:\n",
    "    print(image.shape,label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFRecordDataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description ={\n",
    "    # 定义Feature结构，告诉解码器每个Feature的类型是什么\n",
    "    'image':tf.io.FixedLenFeature([], tf.string),\n",
    "    'label':tf.io.FixedLenFeature([],tf.int64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_example(example_string):\n",
    "    # 将TFRecord文件中的每一个序列化的tf.train.Example解码\n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "    feature_dict['image'] = tf.io.decode_jpeg(feature_dict['image']) #解码JPEG图片\n",
    "    feature_dict['image'] = tf.iamge.resize(feature_dict['image'],[256,256])/255.0 #解码JPEG图片\n",
    "    return feature_dict(['image'],feature_dict['label'])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset('sub_train.tfrecords') # 读取 TFRecord文件\n",
    "\n",
    "train_dataset = train_dataset.map(_parse_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f3a24f9dfa17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for line in train_dataset:\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextLineDataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_lines  = tf.data.TextLineDataset(['./data/titanic/train.csv','./data/titanic/eval.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_func(line):\n",
    "    line = tf.strings.split(line, sep = ',')\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = titanic_lines.skip(1).map(data_func) # 跳过表头名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in titanic_data: # 输出多个Tensor\n",
    "    print(line)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitcb11fcd8cdb441e4bf52994f94e346da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
